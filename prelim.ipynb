{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "# matplotlib inline\n",
    "#%pip install seaborn\n",
    "# import seaborn as sns\n",
    "from shapely.geometry import Point, Polygon\n",
    "import numpy as np\n",
    "%pip install googlemaps\n",
    "import googlemaps\n",
    "from datetime import datetime, timedelta\n",
    "plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "import pandas as pd\n",
    "#%pip install  simplekml\n",
    "import simplekml\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from rasterio.crs import CRS\n",
    "# %pip install rioxarray\n",
    "# %pip install earthpy\n",
    "import rioxarray as rxr\n",
    "import earthpy as et\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import fiona\n",
    "import glob\n",
    "from shapely.geometry import box\n",
    "# import seaborn as sns\n",
    "# import seaborn as sns\n",
    "import os\n",
    "#from whitebox.whitebox_tools import WhiteboxTools\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import folium\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp as mc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 2:**  \n",
    "Consider the ANOVA model given on page 64 of Montgomery's textbook (Equations (3.1) and (3.2))  \n",
    "1. State the statistical assumptions which are usually made when working with this model.  \n",
    "2. Create a Python or Matlab simulation where you specify treatment levels, then draw random numbers appropriately and run a Monte Carlo simulation of such an experiment.  \n",
    "3. Depending on the assumptions you make you should be able to solve the ANOVA problem analytically and then compare the solution and performance with the Monte Carlo result.Explain what you see.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#fff; font-family: 'Babas neue'; font-size: 1.5em;\">Solution part a</span>  \n",
    "The assumptions for analyzing variance of random variables:  \n",
    "- Error is normally distributed  \n",
    "- Error is independently distributed  \n",
    "- Mean error is zero and variance is $\\sigma^{2}$\n",
    "- Random variable is normally and independently distributed with mean $\\mu + \\tau_{i}$ (difference in treatment mean) and variance $\\sigma^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#fff; font-family: 'Babas neue'; font-size: 1.5em;\">Solution part b and c</span>  \n",
    "I have considered the problem of comparing the effect of varying planting days on sseason length of corn (GDD to maturity 2600). Planting date is randomly sselected  from 4 15 day periods from Apr 15th to june 15th for 1000 simulation. These simulations calculate the days for corn to collect 2600 GDD from the historical average temperature. The temperature is the mean daily from 1981 to 2023 scraped from ACIS-RCC for Purdue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# GPS coordinates of Purdue ACRE farm\n",
    "lat = 40.4742259\n",
    "lon = -86.9975974\n",
    "# PRISM goes back to 1981\n",
    "sdate = \"1981-01-01\" #start date for historical data\n",
    "edate = \"2023-12-31\" #end date for historical data\n",
    "# Make ACIS API request\n",
    "w = requests.post('http://data.rcc-acis.org/GridData', json={\n",
    "    \"loc\": f\"{lon}, {lat}\",\n",
    "    \"sdate\": sdate,\n",
    "    \"edate\": edate,\n",
    "    \"grid\": \"21\",   # \"21\" is PRISM\n",
    "    \"elems\": [\n",
    "    # \"maxt\" is maximum temperature at interval daily \n",
    "    #in degree Faherenheit and precipitation in inch\n",
    "        { \"name\":\"maxt\", \"interval\":\"dly\", \"units\":\"degreeF\" }, \n",
    "        { \"name\":\"mint\", \"interval\":\"dly\", \"units\":\"degreeF\" },\n",
    "        { \"name\":\"pcpn\", \"interval\":\"dly\", \"units\":\"inch\" }\n",
    "    ]  \n",
    "})\n",
    "# Parse the JSON response to a Python datatypes\n",
    "w = w.json()\n",
    "#use for loop to print the first 5 items in the retrieved weather data\n",
    "for item in w['data'][0:5]: \n",
    "    print(\"the retrived weather data: \",item)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the raw Python map to a Pandas DataFrame\n",
    "w = pd.DataFrame(w['data'], columns=['date', 'maxt', 'mint', 'pcpn'])\n",
    "w['date'] = pd.to_datetime(w['date'])\n",
    "w.set_index('date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max=84 #maximum temperature for corn growth\n",
    "t_base=50 #base temperature for corn growth\n",
    "w[\"maxt_gd\"]=w[\"maxt\"] #create a new column for max temperature for column operations\n",
    "w[\"mint_gd\"]=w[\"mint\"]#create a new column for min temperature for column operations\n",
    "w.loc[w.maxt_gd > t_max, 'maxt_gd'] = t_max #set the max temperature to 84 if it is greater than 84\n",
    "\n",
    "# Save the daily GDU totals back to the DataFrame as a new column\n",
    "w['gdu'] = (w.maxt_gd + w.mint_gd) / 2 - t_base\n",
    "# Negative GDUs are assumed to be zero ... that is a colder day doesn't reduce the growth\n",
    "w.loc[w.gdu < 0, 'gdu'] = 0 \n",
    "w.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_copy = w.copy()\n",
    "w_copy['avgt'] = (w_copy.mint + w_copy.maxt) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows to modify and then modify them.\n",
    "w_copy.loc[w_copy.mint < 0, 'mint'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of year: Jan 1 -> 0, Jan 2 -> 1, Jan 3 -> 2, ... without regard the actual year\n",
    "byDay = w.groupby(w.index.dayofyear)\n",
    "byDay.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the mean of max temperature, min temperature, GDU and precipitation by day of year\n",
    "byDate_df_mean=pd.concat([byDay.maxt.mean(), byDay.mint.mean(), byDay.gdu.mean(),byDay.pcpn.mean()], axis='columns')\n",
    "byDate_df_mean[\"gdu\"]= byDate_df_mean[\"gdu\"].replace({'0':np.nan, 0:np.nan})#replace 0 with NaN\n",
    "byDate_df_mean[\"gdu_cumsum\"]=byDate_df_mean[\"gdu\"].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthday=[]\n",
    "for day in range(1,367):\n",
    "    monthday_dt=datetime(2020, 1, 1) + timedelta(day- 1)\n",
    "    something=\"2020-\"+str(monthday_dt.month)+\"-\"+str(monthday_dt.day)\n",
    "    monthday.append(something)\n",
    "\n",
    "monthday\n",
    "\n",
    "\n",
    "# month=[]\n",
    "# for day in range(1,367):\n",
    "#     monthday_dt=datetime(2020, 1, 1) + timedelta(day- 1)\n",
    "#     something=str(monthday_dt.month)\n",
    "#     month.append(something)\n",
    "\n",
    "# print(len(monthday))\n",
    "# print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] =600\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "\n",
    "\n",
    "# You can select a column out of the \"GroupBy\" before processing them\n",
    "# You can use the resulting DataFrame just like before, e.g., plotting.\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "\n",
    "plt.errorbar(monthday, byDay.maxt.mean(), byDay.maxt.std(), linewidth =0.5)\n",
    "plt.legend(['Max Temp'])\n",
    "plt.ylabel('Temperature (F)')\n",
    "plt.title('Error bar plot for Average Max daily temperature since 1981')\n",
    "plt.xticks(rotation=25)\n",
    "# ax.set_xlim([monthday[0], monthday[-1]])\n",
    "\n",
    "xfmt = mdates.DateFormatter('%b')\n",
    "months = mdates.MonthLocator()\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_minor_locator(MonthLocator(bymonthday=15))\n",
    "#ax.xaxis.set_major_formatter(xfmt)\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b'))\n",
    "ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "# Hide the last tick label if it is January\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks[:-1])  # Remove the last tick\n",
    "# Now we select the second slice. Notice we share the x-axis. This is so when you interact with the either plot\n",
    "# the other plot is automatically adjusted to the same scale.\n",
    "plt.subplot(3, 1, 2, sharex=ax)\n",
    "plt.plot(byDay.groups.keys(), byDay.gdu.sum(), linewidth=0.5)\n",
    "plt.ylabel('GDD (Tbase=50F)')\n",
    "plt.xticks(rotation=25)\n",
    "\n",
    "plt.subplot(3, 1, 3, sharex=ax)\n",
    "plt.plot( byDay.groups.keys(),byDay.pcpn.sum(), linewidth=0.5)\n",
    "plt.ylabel('Rain (in)')\n",
    "plt.xticks(rotation=25)\n",
    "\n",
    "plt.xlabel('Day of year')\n",
    "plt.title('Mean daily GDU since 1981 ')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weather=w_copy.copy()\n",
    "byDate_df_mean[\"date\"]=monthday\n",
    "byDate_df_mean['date'] = pd.to_datetime(byDate_df_mean['date'])\n",
    "byDate_df_mean.set_index('date', inplace=True)\n",
    "byDate_df_mean[byDate_df_mean.index > \"2020-04-15\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "list_ExperimentDfs=[]\n",
    "\n",
    "# Define a function to calculate GDD accumulation from a given start date\n",
    "def calculate_gdd_accumulation(start_date, gdd_data, target_gdd):\n",
    "    accumulated_gdd = 0\n",
    "    days_count = 0\n",
    "    for index, row in gdd_data.iterrows():\n",
    "        if index >= start_date:\n",
    "            accumulated_gdd += row['gdu']\n",
    "            days_count += 1\n",
    "            if accumulated_gdd >= target_gdd:\n",
    "                break\n",
    "    return days_count\n",
    "\n",
    "\n",
    "def run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd):\n",
    "    simulation_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Calculate the number of days between the start and end date\n",
    "        num_days = (end_date - start_date).days\n",
    "\n",
    "        # Randomly select a day within this range\n",
    "        random_day_within_range = np.random.randint(0, num_days + 1)\n",
    "\n",
    "        # Generate the random planting date within the specified range\n",
    "        random_planting_date = start_date + pd.Timedelta(days=random_day_within_range)\n",
    "\n",
    "        # Calculate the number of days to reach the target GDD\n",
    "        days_to_target_gdd = calculate_gdd_accumulation(random_planting_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "        # Store the result\n",
    "        simulation_results.append((random_planting_date, days_to_target_gdd))\n",
    "\n",
    "    # Convert the simulation results to a DataFrame\n",
    "    simulation_results_df = pd.DataFrame(simulation_results, columns=['Planting Date', 'Days to Target GDD'])\n",
    "    return simulation_results_df\n",
    "\n",
    "# Example usage\n",
    "num_simulations = 1000\n",
    "start_date = pd.Timestamp('2020-04-15')\n",
    "end_date = pd.Timestamp('2020-04-30')\n",
    "\n",
    "target_gdd = 2600\n",
    "\n",
    "# Assuming 'byDate_df_mean' is your DataFrame containing the GDD data\n",
    "# Replace 'byDate_df_mean' with your actual DataFrame variable\n",
    "\n",
    "# Run the simulation\n",
    "simulation_results_df_4 = run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "# Create a list of dates corresponding to the number of days since planting\n",
    "simulation_results_df_4['Date to Target GDD'] = simulation_results_df_4['Planting Date'] + pd.to_timedelta(simulation_results_df_4['Days to Target GDD'], unit='D')\n",
    "\n",
    "#append the resulting dfs to a list for more analysis\n",
    "list_ExperimentDfs.append(simulation_results_df_4)\n",
    "\n",
    "\n",
    "# Convert dates to strings for categorical plotting\n",
    "simulation_results_df_4['Date to Target GDD'] = simulation_results_df_4['Date to Target GDD'].dt.strftime('%m/%d')\n",
    "\n",
    "# Plot the histogram with categorical x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "simulation_results_df_4['Date to Target GDD'].value_counts().sort_index().plot(kind='bar', edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Date to Reach 2600 GDD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Monte Carlo Simulation of Dates to Reach 2600 GDD')\n",
    "\n",
    "# Rotate the date labels for better visibility\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.savefig(\"GDD_MC_0415-0430.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average number of days to reach the target GDD\n",
    "average_days_to_target_gdd = simulation_results_df_4['Days to Target GDD'].mean()\n",
    "print(f'Average number of days to reach 2600 GDD: {average_days_to_target_gdd:.2f} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "list_ExperimentDfs=[]\n",
    "\n",
    "# Define a function to calculate GDD accumulation from a given start date\n",
    "def calculate_gdd_accumulation(start_date, gdd_data, target_gdd):\n",
    "    accumulated_gdd = 0\n",
    "    days_count = 0\n",
    "    for index, row in gdd_data.iterrows():\n",
    "        if index >= start_date:\n",
    "            accumulated_gdd += row['gdu']\n",
    "            days_count += 1\n",
    "            if accumulated_gdd >= target_gdd:\n",
    "                break\n",
    "    return days_count\n",
    "\n",
    "\n",
    "def run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd):\n",
    "    simulation_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Calculate the number of days between the start and end date\n",
    "        num_days = (end_date - start_date).days\n",
    "\n",
    "        # Randomly select a day within this range\n",
    "        random_day_within_range = np.random.randint(0, num_days + 1)\n",
    "\n",
    "        # Generate the random planting date within the specified range\n",
    "        random_planting_date = start_date + pd.Timedelta(days=random_day_within_range)\n",
    "\n",
    "        # Calculate the number of days to reach the target GDD\n",
    "        days_to_target_gdd = calculate_gdd_accumulation(random_planting_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "        # Store the result\n",
    "        simulation_results.append((random_planting_date, days_to_target_gdd))\n",
    "\n",
    "    # Convert the simulation results to a DataFrame\n",
    "    simulation_results_df = pd.DataFrame(simulation_results, columns=['Planting Date', 'Days to Target GDD'])\n",
    "    return simulation_results_df\n",
    "\n",
    "# Example usage\n",
    "num_simulations = 1000\n",
    "start_date = pd.Timestamp('2020-05-01')\n",
    "end_date = pd.Timestamp('2020-05-15')\n",
    "\n",
    "target_gdd = 2600\n",
    "\n",
    "# Assuming 'byDate_df_mean' is your DataFrame containing the GDD data\n",
    "# Replace 'byDate_df_mean' with your actual DataFrame variable\n",
    "\n",
    "# Run the simulation\n",
    "simulation_results_df_3 = run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "# Create a list of dates corresponding to the number of days since planting\n",
    "simulation_results_df_3['Date to Target GDD'] = simulation_results_df_3['Planting Date'] + pd.to_timedelta(simulation_results_df_3['Days to Target GDD'], unit='D')\n",
    "\n",
    "#append the resulting dfs to a list for more analysis\n",
    "list_ExperimentDfs.append(simulation_results_df_3)\n",
    "\n",
    "\n",
    "# Convert dates to strings for categorical plotting\n",
    "simulation_results_df_3['Date to Target GDD'] = simulation_results_df_3['Date to Target GDD'].dt.strftime('%m/%d')\n",
    "\n",
    "# Plot the histogram with categorical x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "simulation_results_df_3['Date to Target GDD'].value_counts().sort_index().plot(kind='bar', edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Date to Reach 2600 GDD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Monte Carlo Simulation of Dates to Reach 2600 GDD')\n",
    "\n",
    "# Rotate the date labels for better visibility\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.savefig(\"GDD_MC_0501-0515.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average number of days to reach the target GDD\n",
    "average_days_to_target_gdd = simulation_results_df_3['Days to Target GDD'].mean()\n",
    "print(f'Average number of days to reach 2600 GDD: {average_days_to_target_gdd:.2f} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "list_ExperimentDfs=[]\n",
    "\n",
    "# Define a function to calculate GDD accumulation from a given start date\n",
    "def calculate_gdd_accumulation(start_date, gdd_data, target_gdd):\n",
    "    accumulated_gdd = 0\n",
    "    days_count = 0\n",
    "    for index, row in gdd_data.iterrows():\n",
    "        if index >= start_date:\n",
    "            accumulated_gdd += row['gdu']\n",
    "            days_count += 1\n",
    "            if accumulated_gdd >= target_gdd:\n",
    "                break\n",
    "    return days_count\n",
    "\n",
    "\n",
    "def run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd):\n",
    "    simulation_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Calculate the number of days between the start and end date\n",
    "        num_days = (end_date - start_date).days\n",
    "\n",
    "        # Randomly select a day within this range\n",
    "        random_day_within_range = np.random.randint(0, num_days + 1)\n",
    "\n",
    "        # Generate the random planting date within the specified range\n",
    "        random_planting_date = start_date + pd.Timedelta(days=random_day_within_range)\n",
    "\n",
    "        # Calculate the number of days to reach the target GDD\n",
    "        days_to_target_gdd = calculate_gdd_accumulation(random_planting_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "        # Store the result\n",
    "        simulation_results.append((random_planting_date, days_to_target_gdd))\n",
    "\n",
    "    # Convert the simulation results to a DataFrame\n",
    "    simulation_results_df = pd.DataFrame(simulation_results, columns=['Planting Date', 'Days to Target GDD'])\n",
    "    return simulation_results_df\n",
    "\n",
    "# Example usage\n",
    "num_simulations = 1000\n",
    "start_date = pd.Timestamp('2020-05-15')\n",
    "end_date = pd.Timestamp('2020-05-31')\n",
    "\n",
    "target_gdd = 2600\n",
    "\n",
    "# Assuming 'byDate_df_mean' is your DataFrame containing the GDD data\n",
    "# Replace 'byDate_df_mean' with your actual DataFrame variable\n",
    "\n",
    "# Run the simulation\n",
    "simulation_results_df_2 = run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "# Create a list of dates corresponding to the number of days since planting\n",
    "simulation_results_df_2['Date to Target GDD'] = simulation_results_df_2['Planting Date'] + pd.to_timedelta(simulation_results_df_2['Days to Target GDD'], unit='D')\n",
    "\n",
    "#append the resulting dfs to a list for more analysis\n",
    "list_ExperimentDfs.append(simulation_results_df_2)\n",
    "\n",
    "\n",
    "# Convert dates to strings for categorical plotting\n",
    "simulation_results_df_2['Date to Target GDD'] = simulation_results_df_2['Date to Target GDD'].dt.strftime('%m/%d')\n",
    "\n",
    "# Plot the histogram with categorical x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "simulation_results_df_2['Date to Target GDD'].value_counts().sort_index().plot(kind='bar', edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Date to Reach 2600 GDD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Monte Carlo Simulation of Dates to Reach 2600 GDD')\n",
    "\n",
    "# Rotate the date labels for better visibility\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.savefig(\"GDD_MC_0515-0531.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average number of days to reach the target GDD\n",
    "average_days_to_target_gdd = simulation_results_df_2['Days to Target GDD'].mean()\n",
    "print(f'Average number of days to reach 2600 GDD: {average_days_to_target_gdd:.2f} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results_df_2[\"Date to Target GDD\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "list_ExperimentDfs=[]\n",
    "\n",
    "# Define a function to calculate GDD accumulation from a given start date\n",
    "def calculate_gdd_accumulation(start_date, gdd_data, target_gdd):\n",
    "    accumulated_gdd = 0\n",
    "    days_count = 0\n",
    "    for index, row in gdd_data.iterrows():\n",
    "        if index >= start_date:\n",
    "            accumulated_gdd += row['gdu']\n",
    "            days_count += 1\n",
    "            if accumulated_gdd >= target_gdd:\n",
    "                break\n",
    "    return days_count\n",
    "# # Define the target GDD for corn\n",
    "# target_gdd = 2600\n",
    "\n",
    "# # Perform Monte Carlo simulation\n",
    "# simulation_results = []\n",
    "# num_simulations = 10\n",
    "\n",
    "# for _ in range(num_simulations):\n",
    "#     # Define the start and end date for the range\n",
    "#     start_date = pd.Timestamp(year=byDate_df_mean.index.year.min(), month=4, day=15)\n",
    "#     end_date = pd.Timestamp(year=byDate_df_mean.index.year.min(), month=5, day=1)\n",
    "\n",
    "#     # Calculate the number of days between the start and end date\n",
    "#     num_days = (end_date - start_date).days\n",
    "\n",
    "#     # Randomly select a day within this range\n",
    "#     random_day_within_range = np.random.randint(0, num_days + 1)\n",
    "\n",
    "#     # Generate the random planting date within the specified range\n",
    "#     random_planting_date = start_date + pd.Timedelta(days=random_day_within_range)\n",
    "#     print(\"Selected planting date: \",random_planting_date)\n",
    "\n",
    "\n",
    "#     # Calculate the number of days to reach the target GDD\n",
    "#     days_to_target_gdd = calculate_gdd_accumulation(random_planting_date, byDate_df_mean, target_gdd)\n",
    "#     print(\"Calculated maturity: \",days_to_target_gdd)\n",
    "\n",
    "#     # Store the result\n",
    "#     simulation_results.append((random_planting_date, days_to_target_gdd))\n",
    "\n",
    "# # Convert the simulation results to a DataFrame\n",
    "# simulation_results_df = pd.DataFrame(simulation_results, columns=['Planting Date', 'Days to Target GDD'])\n",
    "\n",
    "def run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd):\n",
    "    simulation_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Calculate the number of days between the start and end date\n",
    "        num_days = (end_date - start_date).days\n",
    "\n",
    "        # Randomly select a day within this range\n",
    "        random_day_within_range = np.random.randint(0, num_days + 1)\n",
    "\n",
    "        # Generate the random planting date within the specified range\n",
    "        random_planting_date = start_date + pd.Timedelta(days=random_day_within_range)\n",
    "\n",
    "        # Calculate the number of days to reach the target GDD\n",
    "        days_to_target_gdd = calculate_gdd_accumulation(random_planting_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "        # Store the result\n",
    "        simulation_results.append((random_planting_date, days_to_target_gdd))\n",
    "\n",
    "    # Convert the simulation results to a DataFrame\n",
    "    simulation_results_df = pd.DataFrame(simulation_results, columns=['Planting Date', 'Days to Target GDD'])\n",
    "    return simulation_results_df\n",
    "\n",
    "# Example usage\n",
    "num_simulations = 1000\n",
    "start_date = pd.Timestamp('2020-06-01')\n",
    "end_date = pd.Timestamp('2020-06-15')\n",
    "\n",
    "target_gdd = 2600\n",
    "\n",
    "# Assuming 'byDate_df_mean' is your DataFrame containing the GDD data\n",
    "# Replace 'byDate_df_mean' with your actual DataFrame variable\n",
    "\n",
    "# Run the simulation\n",
    "simulation_results_df = run_gdd_simulation(num_simulations, start_date, end_date, byDate_df_mean, target_gdd)\n",
    "\n",
    "# Create a list of dates corresponding to the number of days since planting\n",
    "simulation_results_df['Date to Target GDD'] = simulation_results_df['Planting Date'] + pd.to_timedelta(simulation_results_df['Days to Target GDD'], unit='D')\n",
    "\n",
    "#append the resulting dfs to a list for more analysis\n",
    "list_ExperimentDfs.append(simulation_results_df)\n",
    "\n",
    "\n",
    "# Convert dates to strings for categorical plotting\n",
    "simulation_results_df['Date to Target GDD'] = simulation_results_df['Date to Target GDD'].dt.strftime('%m/%d')\n",
    "\n",
    "# Plot the histogram with categorical x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "simulation_results_df['Date to Target GDD'].value_counts().sort_index().plot(kind='bar', edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Date to Reach 2600 GDD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Monte Carlo Simulation of Dates to Reach 2600 GDD')\n",
    "\n",
    "# Rotate the date labels for better visibility\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.savefig(\"GDD_MC_0601-0615.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average number of days to reach the target GDD\n",
    "average_days_to_target_gdd = simulation_results_df['Days to Target GDD'].mean()\n",
    "print(f'Average number of days to reach 2600 GDD: {average_days_to_target_gdd:.2f} days')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the boxplot illustrates the difference in the average number of days taken by corn to store 2600 GDD when planted in 4 different date ranges. The Corn planted in May 1-15 seems to take the least time.The corn planted in lat may uses the second least number of days but is prone to variability due to weather. Early july crops take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Define the starting date\n",
    "start_date = datetime.datetime(2020, 6, 13)\n",
    "\n",
    "# Calculate the date 200 days after the starting date\n",
    "end_date = start_date + datetime.timedelta(days=200)\n",
    "\n",
    "print(end_date.strftime('%Y-%m-%d'))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Combine the dataframes into a single dataframe with a column indicating the source dataframe\n",
    "simulation_results_df['Source'] = '0601-0615'\n",
    "simulation_results_df_2['Source'] = '0515-0531'\n",
    "simulation_results_df_3['Source'] = '0501-0515'\n",
    "simulation_results_df_4['Source'] = '0415-0430'\n",
    "\n",
    "combined_df = pd.concat([simulation_results_df_4, simulation_results_df_3, simulation_results_df_2, simulation_results_df])\n",
    "\n",
    "# Plot the boxplot\n",
    "plt.figure(figsize=(4, 3))\n",
    "combined_df.boxplot(column='Days to Target GDD', by='Source', grid=False)\n",
    "\n",
    "# Calculate and plot the means\n",
    "means = combined_df.groupby('Source')['Days to Target GDD'].mean()\n",
    "plt.plot(range(1, len(means) + 1), means, color='deeppink', marker='^', linestyle='-', linewidth=1, markersize=5, label='Mean')\n",
    "\n",
    "\n",
    "plt.title('Boxplot of Days to Target GDD ')\n",
    "plt.suptitle('')  # Suppress the default title\n",
    "plt.xlabel('planting date range')\n",
    "plt.ylabel('Days to Target GDD')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df_anova=combined_df.copy()\n",
    "combined_df_anova.columns=combined_df_anova.columns.str.replace(\" \",\"\")\n",
    "combined_df_anova.head()\n",
    "#yield_gott93.columns = yield_gott93.columns.str.replace(' ', '') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the anova analysis of the effect of planting date range on the number of days required for corn to accumulate 2600 gdd controlled by historical weather.\n",
    "model = ols('DaystoTargetGDD ~ C(Source)', data=combined_df_anova).fit()\n",
    "print(\"model parameters\",model.summary())\n",
    "# Perform one-way ANOVA, typ=2 is for both direction testin gof hypothesis.\n",
    "anova_results = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The very high F stat value and its low probability (>0.05) shows the significant difference in the number of days taken by corn to gather 2600 GDD when planted in late april, vs June and early july."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect size of the varibles is used to calculate how much variation in the samples is caused due to the treatments. According to Cohen  \n",
    "- effect size <0.2 small effect size (not much significance)\n",
    "-  0.2< effect size <0.8 medium effect size\n",
    "-  effect size > 0.8 large effect (significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cohend(data1, data2):\n",
    "    from numpy import mean\n",
    "    from numpy import var\n",
    "    from math import sqrt\n",
    "\t# calculate the size of samples\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "\t# calculate the variance of the samples\n",
    "    s1, s2 = var(data1, ddof=1), var(data2, ddof=1)\n",
    "\t# calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\t# calculate the means of the samples\n",
    "    u1, u2 = mean(data1), mean(data2)\n",
    "\t# calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "for row in range(len(list(combined_df_anova[\"Source\"].unique()))):\n",
    "    df=pd.DataFrame()\n",
    "    df1=pd.DataFrame()\n",
    "    groupeddf=combined_df_anova.groupby(\"Source\")\n",
    "    df=groupeddf.get_group(list(combined_df_anova[\"Source\"].unique())[row])\n",
    "    #print(df.head())\n",
    "    d1=df[\"DaystoTargetGDD\"]\n",
    "    df1=groupeddf.get_group(list(combined_df_anova[\"Source\"].unique())[row+1])\n",
    "    d2=df1[\"DaystoTargetGDD\"]\n",
    "    effectsize=cohend(d1,d2)\n",
    "    print(\"effect size:  \", effectsize)\n",
    "import statsmodels.stats.power as smp\n",
    "\n",
    "# Set parameters\n",
    "effect_size = 3.38  # Desired effect size (e.g., Cohen's d). \n",
    "alpha = 0.05       # Significance level\n",
    "k_groups = 4       # Number of groups in the ANOVA\n",
    "nobs = 3997        # Total sample size (across all groups)\n",
    "\n",
    "# Create an FTestAnovaPower object\n",
    "power_analysis = smp.FTestAnovaPower()\n",
    "\n",
    "# Calculate power\n",
    "power = power_analysis.power(effect_size, nobs, alpha, k_groups)\n",
    "\n",
    "print(f\"Power: {power}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dont worry about the error here; its by design.**  \n",
    "### The Effect size of all three pairs are high according to Cohen's range of effect sizes. This suggests the planting dates are significant in deciding the number of days for corn to collect 2600 GDD. The effect size supports the ANOVA analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `The graph below shows the GDD though out the years from 1981 to 2023.The avrage GDD is in green. The GDD is calculated from May1st corn (2600 GDD).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "\n",
    "# Planting date\n",
    "planting_date = pd.Timestamp(year=w_copy.index.year.min(), month=4, day=30)\n",
    "\n",
    "# Calculate daily GDU accumulation\n",
    "w_copy['Cumulative GDU'] = w_copy.groupby(w_copy.index.year)['gdu'].cumsum()\n",
    "filtered_w_copy = w_copy[w_copy['Cumulative GDU'] <= 2600]\n",
    "\n",
    "# Determine the range of GDU accumulation for all years\n",
    "gdu_by_day = filtered_w_copy.groupby(filtered_w_copy.index.dayofyear)['Cumulative GDU']\n",
    "gdu_min = gdu_by_day.min()\n",
    "gdu_max = gdu_by_day.max()\n",
    "gdu_mean = gdu_by_day.mean()\n",
    "\n",
    "# Create a date range for the x-axis labels dynamically based on the latest date of reaching 2600 GDU\n",
    "end_date = filtered_w_copy.index.max()\n",
    "days_of_year = pd.date_range(start=planting_date, end=end_date, freq='D').dayofyear\n",
    "\n",
    "# Filter out the dates before the planting date\n",
    "gdu_min = gdu_min[gdu_min.index >= planting_date.dayofyear]\n",
    "gdu_max = gdu_max[gdu_max.index >= planting_date.dayofyear]\n",
    "gdu_mean = gdu_mean[gdu_mean.index >= planting_date.dayofyear]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the range of all years in shaded gray\n",
    "plt.fill_between(gdu_min.index, gdu_min, gdu_max, color='gray', alpha=0.3, label='GDU Range (All Years)')\n",
    "\n",
    "# Plot the average GDU accumulation in dark green\n",
    "plt.plot(gdu_mean.index, gdu_mean, color='darkgreen', label='Average GDU (All Years)')\n",
    "\n",
    "# Format the x-axis to show month/day\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "plt.gca().xaxis.set_minor_locator(mdates.WeekdayLocator())\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative GDU')\n",
    "plt.title('GDU Accumulation for Growing Corn (2600 GDU Target)')\n",
    "plt.axhline(y=2600, color='r', linestyle='--', label='2600 GDU Target')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 3:** \n",
    "Consider the soybean yield file (gott east93 2012 harvest.csv). The rows in the file are sequential measurements made by the mass flow sensor in a combine harvester. Each row includes longitude, latitude, speed, and wet and dry yields measured in bushels per acre and pounds per acre. There are other columns as well.  \n",
    "\n",
    "1.  Plot the dry yield map to check how it all looks.  \n",
    "2.  If you wanted to turn the yield rate data into raw yield (i.e., either bushels or pounds), what\n",
    "    transformation would you have to make?  \n",
    "3.  Looking at the yield map you should see various passes through the field. Write some code to\n",
    "    extract the time series corresponding to each pass through the field.  \n",
    "4.  In each time series estimate the mean, variance, and correlation from sample to sample.\n",
    "5.  If we thought of each pass as the result of a separate treatment, how could we apply ANOVA to analyze the         hypothesis that all passes have the same mean? Do it and report the result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#fff; font-family: 'Babas neue'; font-size: 1.5em;\">Solution part 2</span>  \n",
    "\n",
    "converting bu/ac to bushels for soybean  \n",
    "1 bushel of soybean is 60 lbs.  \n",
    "<span style=\"color:#fff; font-family: 'Babas neue'; font-size: 1.5em;\">yield (bu/ac) = $43,560 \\times  \\frac{(m \\times t)}{(d \\times w \\times p)} \\times \\frac{100-MC_{harvest}}{100-MC_{market}}$</span>  \n",
    "\n",
    "m = mass flow rate estimated from the impact plate sensor (lb/sec)  \n",
    "t = Logging interval of the yield monitoring system (sec)  \n",
    "d = distance traveled between logged data points (ft)  \n",
    "w = header cut width setting (ft)  \n",
    "p = grain density or test weight (lb/bu), 60 for soybean  \n",
    "$MC_{harvest}$ = moisture content measurement from the yield monitor moisture sensor (%)  \n",
    "$MC_{market}$ = marketable moisture content (%)  \n",
    "43,560 = conversion from $ft^2$ to acres\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#fff; font-family: 'Babas neue'; font-size: 1.5em;\">Solution part 1,3,4, and 5</span>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_gott93=pd.read_csv(\"Prelim_figs/gott_east93_2012_harvest.csv\",encoding='unicode_escape')\n",
    "yield_gott93.columns = yield_gott93.columns.str.replace(' ', '') \n",
    "\n",
    "yield_gott93.head()\n",
    "yield_gott93.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    yield_gott93, geometry=gpd.points_from_xy(yield_gott93.Longitude, yield_gott93.Latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "soybean_gott=gdf.to_crs(\"EPSG:26916\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"EstimatedVolume(Dry)(bu/ac)\",cmap=\"Greens\", markersize=0.3,legend=True,legend_kwds={\"label\": \"bu/ac\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Dry volume measured from Soybean harvest in 2011\")\n",
    "print(\"Shape: \",soybean_gott.shape)\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"CropFlow(Mass)(lb/s)\",cmap=\"Greens\",markersize=0.3, legend=True,legend_kwds={\"label\": \"lb/s\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Crop flow mass measured in combine during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soybean in 60 lbs per bushel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"Speed(mph)\",cmap=\"Reds\",markersize=0.3, legend=True,legend_kwds={\"label\": \"mph\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Speed measured during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"Moisture(%)\",cmap=\"Blues\",markersize=0.3, legend=True,legend_kwds={\"label\": \"%\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Moisture measured during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"Elevation(ft)\",cmap=\"terrain\",markersize=0.3, legend=True,legend_kwds={\"label\": \"feet\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Elevation measured during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"DifferentialValid\",cmap=\"binary\", markersize=0.3,legend=True, zorder=20)\n",
    "plt.title(\"Differential Validity measured during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.plot(\"SwathWidth(ft)\",cmap=\"Set2\",markersize=0.3, legend=True,legend_kwds={\"label\": \"feet\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Swath Width measured during Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_initial_compass_bearing(pointA, pointB):\n",
    "    import math\n",
    "    \"\"\"\n",
    "    Calculates the bearing between two points.\n",
    "    The formulae used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - `pointA: The tuple representing the latitude/longitude for the\n",
    "        first point. Latitude and longitude must be in decimal degrees\n",
    "      - `pointB: The tuple representing the latitude/longitude for the\n",
    "        second point. Latitude and longitude must be in decimal degrees\n",
    "    :Returns:\n",
    "      The bearing in degrees\n",
    "    :Returns Type:\n",
    "      float\n",
    "    \"\"\"\n",
    "    #use this if the point geometry is in lat\\lon decimal degrees\n",
    "    # pointA = (pointA1.x, pointA1.y)\n",
    "    # pointB = (pointB1.x, pointB1.y)\n",
    "\n",
    "\n",
    "    if (type(pointA) != tuple) or (type(pointB) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "\n",
    "    diffLong = math.radians(pointB[1] - pointA[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing\n",
    "    #return initial_bearing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=[[40.99583,-86.17708],[40.98973,-86.18052],[40.99005,-86.17399]]\n",
    "df=pd.DataFrame(data, columns=[\"Lat\",\"Lon\"])\n",
    "df[\"bearing\"]=np.nan\n",
    "for i in range(len(df[\"Lat\"])-1):\n",
    "    point1=(df[\"Lat\"][i], df[\"Lon\"][i])    \n",
    "    point2=(df[\"Lat\"][i+1], df[\"Lon\"][i+1])\n",
    "    print(point1,point2)\n",
    "    df[\"bearing\"][i]=calculate_initial_compass_bearing(point1,point2)\n",
    "    print(df[\"bearing\"][i])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Lat']\n",
    "Y = df['Lon']\n",
    "U = np.cos(df[\"bearing\"]) \n",
    "V = np.sin(df[\"bearing\"])\n",
    "print(U,V)\n",
    "uvis=U*(np.log(df[\"bearing\"]+10)/np.log(2))\n",
    "vvis=V*(np.log(df[\"bearing\"]+10)/np.log(2))\n",
    "\n",
    "uvisA= uvis*(100/df[\"bearing\"].max())\n",
    "vvisA= vvis*(100/df[\"bearing\"].max())\n",
    "fig, ax1 = plt.subplots(1)\n",
    "q=ax1.quiver(X,Y,uvisA,vvisA, zorder=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott[\"bearing\"]=np.nan\n",
    "for i in range(len(soybean_gott[\"geometry\"])-1):\n",
    "    point1=(soybean_gott[\"Latitude\"][i], soybean_gott[\"Longitude\"][i])    \n",
    "    point2=(soybean_gott[\"Latitude\"][i+1], soybean_gott[\"Longitude\"][i+1])\n",
    "    soybean_gott[\"bearing\"][i]=calculate_initial_compass_bearing(point1,point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gott93 = folium.Map(location=[40.991725, -86.182159], tiles=\"CartoDB Positron\", zoom_start=12)\n",
    "# gott93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yp_gjson = folium.features.GeoJson(soybean_gott, name=\"Gott 93 yield\")\n",
    "# yp_gjson.add_to(gott93)\n",
    "# gott93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott_resampled=soybean_gott.sample(frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= soybean_gott_resampled['geometry'].x\n",
    "Y = soybean_gott_resampled['geometry'].y\n",
    "U = np.cos(soybean_gott_resampled[\"bearing\"]) \n",
    "V = np.sin(soybean_gott_resampled[\"bearing\"])\n",
    "#print(U,V)\n",
    "uvis=U*(np.log(soybean_gott_resampled[\"bearing\"]+10)/np.log(2))\n",
    "vvis=V*(np.log(soybean_gott_resampled[\"bearing\"]+10)/np.log(2))\n",
    "\n",
    "uvisA= uvis*(100/soybean_gott_resampled[\"bearing\"].max())\n",
    "vvisA= vvis*(100/soybean_gott_resampled[\"bearing\"].max())\n",
    "myax=soybean_gott_resampled.plot(\"Speed(mph)\",cmap=\"Reds\",markersize=0.5, legend=True,legend_kwds={\"label\": \"mph\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "ax1=myax\n",
    "q=ax1.quiver(X,Y,uvisA,vvisA, zorder=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soybean_gott_resampled[\"bearing\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "exSite1_latlon=[[-86.17915, 40.99286],[-86.17822,40.9929],[-86.17956,40.98973],[-86.18045,40.98973],[-86.17915,40.99286]]\n",
    "polygon_geom=Polygon(exSite1_latlon)\n",
    "exSite1=gpd.GeoDataFrame(crs=\"EPSG:4326\", geometry=[polygon_geom])\n",
    "exSite1_UTM=exSite1.to_crs(crs=\"EPSG:26916\")\n",
    "exSite1_UTM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "exSite2_latlon=[[-86.17448, 40.99478],[-86.17375,40.99469],[-86.17583,40.98974],[-86.17671,40.98975],[-86.17448, 40.99478]]\n",
    "polygon_geom=Polygon(exSite2_latlon)\n",
    "exSite2=gpd.GeoDataFrame(crs=\"EPSG:4326\", geometry=[polygon_geom])\n",
    "exSite2_UTM=exSite2.to_crs(crs=\"EPSG:26916\")\n",
    "exSite2_UTM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myax=soybean_gott.plot(\"YieldMass(Dry)(lb/ac)\",cmap=\"Greens\", markersize=0.3,legend=True,legend_kwds={\"label\": \"lb/ac\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30}, zorder=20)\n",
    "plt.title(\"Dry Yield measured from Soybean harvest in 2011\")\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5, alpha=0.3)\n",
    "#myax=ax1\n",
    "exSite1_UTM.plot(ax=myax, color=\"None\", edgecolor=\"blue\",zorder=21 )\n",
    "exSite2_UTM.plot(ax=myax, color=\"None\", edgecolor=\"deeppink\",zorder=21 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \",soybean_gott.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott_site1=soybean_gott.clip(exSite1_UTM.buffer(1.5))\n",
    "bins=6\n",
    "colors_yield = plt.cm.brg(np.linspace(0.55, 1, bins+1))\n",
    "yield_map = colors.LinearSegmentedColormap.from_list('yield_map', colors_yield)\n",
    "soybean_gott_site1.plot(\"EstimatedVolume(Dry)(bu/ac)\",cmap=yield_map,markersize=0.5, legend=\"True\",legend_kwds={\"label\": \"bu/ac\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \",soybean_gott_site1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapecreator(bboxfieldShapeUTM):\n",
    "    clipper = box(bboxfieldShapeUTM[0],bboxfieldShapeUTM[1],bboxfieldShapeUTM[2],bboxfieldShapeUTM[3])\n",
    "    fieldClipper = gpd.GeoDataFrame(index=[0], geometry=[clipper])\n",
    "    bins=6\n",
    "    colors_yield = plt.cm.brg(np.linspace(0.55, 1, bins+1))\n",
    "    yield_map = colors.LinearSegmentedColormap.from_list('yield_map', colors_yield)\n",
    "    ax=soybean_gott_site1.plot(\"EstimatedVolume(Dry)(bu/ac)\",cmap=yield_map,markersize=0.5, legend=\"True\",legend_kwds={\"label\": \"bu/ac\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30})\n",
    "    fieldClipperRotated=fieldClipper.rotate(angle=-17,origin=(float(bboxfieldShapeUTM[0]-5),float(bboxfieldShapeUTM[1])))\n",
    "    fieldClipperRotated.plot(ax=ax,color=\"None\",edgecolor=\"deeppink\")\n",
    "    return fieldClipperRotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_gott_site1=soybean_gott_site1[soybean_gott_site1[\"EstimatedVolume(Dry)(bu/ac)\"] < soybean_gott_site1[\"EstimatedVolume(Dry)(bu/ac)\"].quantile(0.999)]\n",
    "soybean_gott_site1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape=exSite1_UTM.buffer(1.5)\n",
    "exsite1_shape1_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]-5),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+7),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+14)\n",
    "exsite1_shape1=shapecreator(exsite1_shape1_bounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape2_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+7),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+15),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+16)\n",
    "exsite1_shape2=shapecreator(exsite1_shape2_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape3_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+17),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+27),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+16)\n",
    "exsite1_shape3=shapecreator(exsite1_shape3_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape4_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+27),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+37),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+20)\n",
    "exsite1_shape4=shapecreator(exsite1_shape4_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape5_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+37),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+47),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+16)\n",
    "exsite1_shape5=shapecreator(exsite1_shape5_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape6_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+50),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+60),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+20)\n",
    "exsite1_shape6=shapecreator(exsite1_shape6_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape7_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+60),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+70),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+20)\n",
    "exsite1_shape7=shapecreator(exsite1_shape7_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsite1_shape8_bounds=float(exsite1_shape.bounds[\"minx\"].iloc[0]+70),float(exsite1_shape.bounds[\"miny\"].iloc[0]),float(exsite1_shape.bounds[\"minx\"].iloc[0]+80),float(exsite1_shape.bounds[\"maxy\"].iloc[0]+20)\n",
    "exsite1_shape8=shapecreator(exsite1_shape8_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exSite1_row1=soybean_gott_site1.clip(exsite1_shape1) \n",
    "exSite1_row1[\"Row\"]=1\n",
    "print(exSite1_row1.shape)\n",
    "exSite1_row2=soybean_gott_site1.clip(exsite1_shape2) \n",
    "exSite1_row2[\"Row\"]=2\n",
    "print(exSite1_row2.shape)\n",
    "exSite1_row3=soybean_gott_site1.clip(exsite1_shape3) \n",
    "exSite1_row3[\"Row\"]=3\n",
    "print(exSite1_row3.shape)\n",
    "exSite1_row4=soybean_gott_site1.clip(exsite1_shape4) \n",
    "exSite1_row4[\"Row\"]=4\n",
    "print(exSite1_row4.shape)\n",
    "exSite1_row5=soybean_gott_site1.clip(exsite1_shape5) \n",
    "exSite1_row5[\"Row\"]=5\n",
    "print(exSite1_row5.shape)\n",
    "exSite1_row6=soybean_gott_site1.clip(exsite1_shape6) \n",
    "exSite1_row6[\"Row\"]=6\n",
    "print(exSite1_row6.shape)\n",
    "exSite1_row7=soybean_gott_site1.clip(exsite1_shape7) \n",
    "exSite1_row7[\"Row\"]=7\n",
    "print(exSite1_row7.shape)\n",
    "exSite1_row8=soybean_gott_site1.clip(exsite1_shape8) \n",
    "exSite1_row8[\"Row\"]=8\n",
    "print(exSite1_row8.shape)\n",
    "list_rows=[exSite1_row1,exSite1_row2,exSite1_row3,exSite1_row4,exSite1_row5,exSite1_row6,exSite1_row7,exSite1_row8]\n",
    "experimentSite1=pd.concat(list_rows)\n",
    "experimentSite1.shape\n",
    "#print(experimentSite1.head())\n",
    "#print(\"the mean of the row 8 in experiment site 1 = \",round(exSite1_row8[\"EstimatedVolume(Dry)(bu/ac)\"].mean(),2))\n",
    "#print(\"the variance of the row 8 in experiment site 1 = \",round(pow(exSite1_row8[\"EstimatedVolume(Dry)(bu/ac)\"].std(),2),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(experimentSite1.groupby(\"Row\")[\"EstimatedVolume(Dry)(bu/ac)\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pow(experimentSite1.groupby(\"Row\")[\"EstimatedVolume(Dry)(bu/ac)\"].std(),2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentSite1[\"Row\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site=experimentSite1.groupby(\"Row\")\n",
    "#site.plot(\"Estimated Volume (Dry)(bu/ac)\")\n",
    "for key, item in site:\n",
    "    print(item.shape)\n",
    "    #print(site.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in site:\n",
    "    print(key)\n",
    "    print(site.get_group(key).shape)\n",
    "site.get_group(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr=[]\n",
    "for row in range(1,9):\n",
    "    print(site.get_group(row).shape)\n",
    "    list_corr.append(round(site.get_group(row)[\"EstimatedVolume(Dry)(bu/ac)\"].autocorr(lag=1),2))\n",
    "print(list_corr) \n",
    "corr_arr=np.array(list_corr)\n",
    "fig, ax = plt.subplots()\n",
    "x=np.arange(1,9)\n",
    "ax=plt.plot(x,corr_arr)\n",
    "plt.xticks(x,(\"row1\",\"row2\",\"row3\",\"row4\",\"row5\",\"row6\",\"row7\",\"row8\"))\n",
    "plt.ylabel(\"lag 1 correlation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr=[]\n",
    "for row in range(1,9):\n",
    "    list_corr.append(round(site.get_group(row)[\"EstimatedVolume(Dry)(bu/ac)\"].mean(),2))\n",
    "print(list_corr) \n",
    "corr_arr=np.array(list_corr)\n",
    "fig, ax = plt.subplots()\n",
    "x=np.arange(1,9)\n",
    "ax=plt.plot(x,corr_arr)\n",
    "plt.xticks(x,(\"row1\",\"row2\",\"row3\",\"row4\",\"row5\",\"row6\",\"row7\",\"row8\"))\n",
    "plt.ylabel(\"mean yield (bu/ac)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr=[]\n",
    "for row in range(1,9):\n",
    "    list_corr.append(round(pow(site.get_group(row)[\"EstimatedVolume(Dry)(bu/ac)\"].std(),2),2))\n",
    "print(list_corr) \n",
    "corr_arr=np.array(list_corr)\n",
    "fig, ax = plt.subplots()\n",
    "x=np.arange(1,9)\n",
    "ax=plt.plot(x,corr_arr)\n",
    "plt.xticks(x,(\"row1\",\"row2\",\"row3\",\"row4\",\"row5\",\"row6\",\"row7\",\"row8\"))\n",
    "plt.ylabel(\"variance of yield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site1_treatment=[]\n",
    "treatmentList=[\"F\",\"M\",\"F\",\"M\",\"F\",\"M\",\"F\",\"M\"]\n",
    "for row in range(1,9):\n",
    "    df=site.get_group(row)\n",
    "    print(df.shape)\n",
    "    df[\"treatment\"]=treatmentList[row-1]\n",
    "    site1_treatment.append(df)\n",
    "site1_treatment_df=pd.concat(site1_treatment)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site1_treatment_df=site1_treatment_df.rename(columns={\"EstimatedVolume(Dry)(bu/ac)\": \"EstimatedVolume\"})\n",
    "experiment_dict={1:\"Ex1\",2:\"Ex1\",3:\"Ex2\",4:\"Ex2\",5:\"Ex3\",6:\"Ex3\",7:\"Ex4\",8:\"Ex4\"}\n",
    "site1_treatment_df[\"Replicate\"]=site1_treatment_df[\"Row\"].map(experiment_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site1_treatment_df[\"Row\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfanova=site1_treatment_df[[\"EstimatedVolume\",\"treatment\",\"Replicate\"]].copy()\n",
    "dfanova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteTreatment=dfanova.groupby(\"Replicate\")\n",
    "siteTreatment.get_group(\"Ex1\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentDesigner(experimentlist,treatmentList):\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    mpl.rcParams['hatch.linewidth'] = 0.5\n",
    "    experiment_dict={\"Ex1\":\"deeppink\",\"Ex2\":\"blue\",\"Ex3\":\"Red\",\"Ex4\":\"Black\"}\n",
    "    treatment_dict={\"F\":'xx',\"M\":'oo'}\n",
    "    bins=6\n",
    "    colors_yield = plt.cm.brg(np.linspace(0.55, 1, bins+1))\n",
    "    yield_map = colors.LinearSegmentedColormap.from_list('yield_map', colors_yield)\n",
    "    ax=soybean_gott_site1.plot(\"EstimatedVolume(Dry)(bu/ac)\",cmap=yield_map,markersize=0.5, legend=\"True\",legend_kwds={\"label\": \"bu/ac\",\"fmt\": \"{:.1f}\", \"orientation\": \"vertical\", 'shrink':0.5, 'aspect':30})\n",
    "    exsite1_shape1.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[0]], hatch = treatment_dict[treatmentList[0]])\n",
    "    exsite1_shape2.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[0]], hatch = treatment_dict[treatmentList[1]])\n",
    "    exsite1_shape3.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[1]], hatch = treatment_dict[treatmentList[2]])\n",
    "    exsite1_shape4.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[1]], hatch = treatment_dict[treatmentList[3]])\n",
    "    exsite1_shape5.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[2]], hatch = treatment_dict[treatmentList[4]])\n",
    "    exsite1_shape6.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[2]], hatch = treatment_dict[treatmentList[5]])\n",
    "    exsite1_shape7.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[3]], hatch = treatment_dict[treatmentList[6]])\n",
    "    exsite1_shape8.plot(ax=ax,color=\"None\",edgecolor=experiment_dict[experimentlist[3]], hatch = treatment_dict[treatmentList[7]])\n",
    "    plt.title(\"Experiment design at Experimental Site 1\")\n",
    "    rect1 = mpatches.Patch( facecolor=\"None\",edgecolor=experiment_dict[\"Ex1\"],label='Rep 1')\n",
    "    rect2= mpatches.Patch( facecolor=\"None\",edgecolor=experiment_dict[\"Ex2\"],label='Rep 2')\n",
    "    rect3 = mpatches.Patch(facecolor=\"None\",edgecolor=experiment_dict[\"Ex3\"],label='Rep 3')\n",
    "    rect4 = mpatches.Patch(facecolor=\"None\",edgecolor=experiment_dict[\"Ex4\"],label='Rep 4')\n",
    "    rect5 = mpatches.Patch(edgecolor= \"black\",facecolor=\"None\",hatch='xx',label='Trt 1')\n",
    "    rect6 = mpatches.Patch(edgecolor= \"black\",facecolor=\"None\",hatch='oo',label='Trt 2')\n",
    "    ax.legend(handles = [rect1,rect2,rect3,rect4,rect5,rect6],loc=4)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have designed an experiment too compare effect of fertlizer(trt1) vs Manure(trt2) on soybean. Experiment site 1 was chosen because of its least varibility in all other factors during yield collection. The experiment has 4 replicates which are placed side by side with no spatial randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentlist=[\"Ex1\",\"Ex2\",\"Ex3\",\"Ex4\"]\n",
    "\n",
    "experimentDesigner(experimentlist,treatmentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteTreatment=dfanova.groupby(\"Replicate\")\n",
    "for ex in experimentlist:\n",
    "        df=pd.DataFrame()\n",
    "        df=siteTreatment.get_group(ex)\n",
    "        print(df.shape)\n",
    "        #print(ex)\n",
    "        # the \"C\" in C(drainageclabbrvt) is defining it as a categorical variable. hence it is very important here. \n",
    "        model = ols('EstimatedVolume ~ C(treatment)', data=df).fit()\n",
    "        #print(\"model parameters\",model.summary())\n",
    "        # Perform one-way ANOVA, typ=2 is for both direction testin gof hypothesis.\n",
    "        anova_results = sm.stats.anova_lm(model, typ=2)\n",
    "        print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At $\\alpha =0.05$ the treament mean is significant between Manure and fertlizer in all 4 replicates. However their effect size is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohend(data1, data2):\n",
    "    from numpy import mean\n",
    "    from numpy import var\n",
    "    from math import sqrt\n",
    "\t# calculate the size of samples\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "\t# calculate the variance of the samples\n",
    "    s1, s2 = var(data1, ddof=1), var(data2, ddof=1)\n",
    "\t# calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\t# calculate the means of the samples\n",
    "    u1, u2 = mean(data1), mean(data2)\n",
    "\t# calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "for row in range(1,8):\n",
    "    df=pd.DataFrame()\n",
    "    df1=pd.DataFrame()\n",
    "    df=site.get_group(row)\n",
    "    #print(df.head())\n",
    "    d1=df[\"EstimatedVolume(Dry)(bu/ac)\"]\n",
    "    df1=site.get_group(row+1)\n",
    "    d2=df1[\"EstimatedVolume(Dry)(bu/ac)\"]\n",
    "    effectsize=cohend(d1,d2)\n",
    "    print(\"effect size:  \", effectsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.power as smp\n",
    "\n",
    "# Set parameters\n",
    "effect_size = 0.2  # Desired effect size (e.g., Cohen's f)\n",
    "alpha = 0.05       # Significance level\n",
    "k_groups = 2       # Number of groups in the ANOVA\n",
    "nobs = 568        # Total sample size (across all groups)\n",
    "\n",
    "# Create an FTestAnovaPower object\n",
    "power_analysis = smp.FTestAnovaPower()\n",
    "\n",
    "# Calculate power\n",
    "power = power_analysis.power(effect_size, nobs, alpha, k_groups)\n",
    "\n",
    "print(f\"Power: {power}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "eta_squared (float): ANOVA effect size (eta-squared).\n",
    "\n",
    "k (int): Number of groups\n",
    "\n",
    "n (int): Sample size per group. Groups are assumed to be balanced (i.e. same sample size).\n",
    "\n",
    "power (float) :Test power (= 1 - type II error).\n",
    "\n",
    "alpha (float) : Significance level (type I error probability). The default is 0.05.\"\"\"\n",
    "from pingouin import power_anova\n",
    "print('n: %.4f' % power_anova(eta_squared=0.2237,k=2,power=.99, alpha=0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('.venv31013': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5587e4926b52c423561cb3fcc0a91d113b7a3be1aa82022008258402de83f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
